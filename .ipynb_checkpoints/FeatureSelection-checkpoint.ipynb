{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "234f5f10-8b64-47c7-843e-71cb1f0869c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1816ebf1-c2ae-4164-812c-bd91b43cf895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ALLSKY_SFC_LW_DWN  PRECTOT     PS   QV2M  RH2M  SRF_ALB  T10M  T10M_MAX  \\\n",
      "0               5.87     3.13  19.25  10.63  4.32    28.10  0.49      2.06   \n",
      "1               1.38     1.81  28.12  11.24  0.98    18.91  0.00      0.46   \n",
      "2               3.09     4.40  22.81  17.17  2.47    32.38  1.65      2.57   \n",
      "3               3.05     5.91  89.62   4.05  2.06    16.52  3.51      4.33   \n",
      "4               3.32     1.95  30.00   7.81  0.95    15.08  0.20      0.63   \n",
      "\n",
      "   T10M_MIN  T10M_RANGE  ...  TROPQ  TROPT  TOA_SW_DNI  TOA_SW_DWN  \\\n",
      "0      0.88        4.81  ...   0.01 -68.68       17.52        8.81   \n",
      "1      0.93        0.98  ...   0.01 -61.99       17.45        8.71   \n",
      "2      3.45        4.12  ...   0.01 -67.51       17.43        9.15   \n",
      "3      4.73        5.57  ...   0.01 -70.45       18.62       10.02   \n",
      "4      0.30        1.15  ...   0.02 -58.15       16.20        8.23   \n",
      "\n",
      "   CLRSKY_SFC_PAR_TOT  EVPTRNS  PBLTOP  Longitude  Latitude  Fire  \n",
      "0              116.92      0.0   81.98   -116.700    33.862     1  \n",
      "1               83.10      0.0   86.33   -123.000    39.855     1  \n",
      "2              119.66      0.0   76.73   -121.473    36.068     1  \n",
      "3              129.61      0.0   98.29   -121.608    36.151     1  \n",
      "4              100.30      0.0   74.84   -119.435    37.286     1  \n",
      "\n",
      "[5 rows x 59 columns]\n",
      "Index(['ALLSKY_SFC_LW_DWN', 'PRECTOT', 'PS', 'QV2M', 'RH2M', 'SRF_ALB', 'T10M',\n",
      "       'T10M_MAX', 'T10M_MIN', 'T10M_RANGE', 'TQV', 'TS', 'WS10M', 'WS10M_MAX',\n",
      "       'WS10M_MIN', 'WS10M_RANGE', 'WS2M', 'WS2M_MAX', 'WS2M_MIN',\n",
      "       'WS2M_RANGE', 'U10M', 'V10M', 'AIRMASS', 'TS_MAX', 'TS_MIN', 'TS_RANGE',\n",
      "       'T2MWET', 'DIRECT_ILLUMINANCE', 'DIFFUSE_ILLUMINANCE', 'PW',\n",
      "       'ALLSKY_SFC_UV_INDEX', 'GWETPROF', 'SNODP', 'GWETROOT', 'SLP', 'RHOA',\n",
      "       'Z0M', 'GWETTOP', 'TO3', 'T2M', 'T2MDEW', 'T2M_RANGE', 'T2M_MAX',\n",
      "       'T2M_MIN', 'DIFF', 'DNR', 'ALLSKY_SFC_UVA', 'ALLSKY_SFC_UVB', 'TROPPB',\n",
      "       'TROPQ', 'TROPT', 'TOA_SW_DNI', 'TOA_SW_DWN', 'CLRSKY_SFC_PAR_TOT',\n",
      "       'EVPTRNS', 'PBLTOP', 'Longitude', 'Latitude', 'Fire'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "fires = pd.read_csv('4Gridded_Small_Fires.csv')\n",
    "#Small dataset with tempFires appaerntly worse off\n",
    "\n",
    "fires = fires.drop(['Unnamed: 0', 'Datetime', 'YEAR', 'MO', 'DY'], axis = 1)\n",
    "print(fires.head())\n",
    "print(fires.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a77642f-7dfb-4fd5-897a-984c224ff910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10247, 58)\n",
      "(2562, 58)\n",
      "(10247,)\n",
      "(2562,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "x = fires.drop(['Fire'], axis = 1)\n",
    "y = fires['Fire']\n",
    "\n",
    "x = standardizer.fit_transform(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "590d560b-e6b0-4e35-9533-078f40ae3e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9652615144418423\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=10000)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print(model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77c9d498-887e-4007-950c-9ce77c28bb56",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only integers accepted as `n` values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-16daf2532226>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfires\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfires\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis)\u001b[0m\n\u001b[1;32m   5336\u001b[0m             )\n\u001b[1;32m   5337\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfrac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5338\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Only integers accepted as `n` values\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5339\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfrac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5340\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maxis_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Only integers accepted as `n` values"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b6f00d03-b89c-4cd2-bb82-737fe2c76746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better subset found on generation 0 with score of 0.9352068696330992\n",
      "Better subset found on generation 42 with score of 0.9395003903200625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "\n",
    "#Randomized Hill Climbing Subset-Select Algorithm\n",
    "#Feature Selection based on Randomized Hill-Climbing Heuristic\n",
    "\n",
    "#Global Variables\n",
    "x_RHCSS = x\n",
    "y_RHCSS = y\n",
    "sz = x.shape[1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_RHCSS, y_RHCSS, test_size=0.2, random_state=69)\n",
    "\n",
    "#Alpha Level, [0, 0.5)\n",
    "alpha = 0.5\n",
    "#a% to switch\n",
    "#100-a% to remain\n",
    "\n",
    "evaluation_function = accuracy_score\n",
    "# model_algorithm = RandomForestClassifier\n",
    "model_algorithm = DecisionTreeClassifier\n",
    "\n",
    "def score(a, b):\n",
    "    if len(a) == 0:\n",
    "        #If we have no features (bitstring = 0), the score is automatically 0\n",
    "        return 0\n",
    "    \n",
    "    model = model_algorithm()\n",
    "    \n",
    "    model.fit(a, y_train)\n",
    "    \n",
    "    pred = model.predict(b)\n",
    "    #PREDICTION, Y_TEST OR OTHER WAY AROUND?\n",
    "    return evaluation_function(pred, y_test)\n",
    "    \n",
    "#Generation - Depth of the selection tree\n",
    "#We select the best children from each generation and continue with it\n",
    "\n",
    "def RHCSS(generations=100, verbose = 1):\n",
    "    #Keep running track of the best state we found so far\n",
    "    #We use a bitset to represent wether the each feature is included\n",
    "    best = (0, [0] * sz)\n",
    "    \n",
    "    for i in range(generations):\n",
    "        current_state = best[1]\n",
    "        \n",
    "        #The features to exclude\n",
    "        drops = []\n",
    "        \n",
    "        #Each generation, we mutate the best state\n",
    "        for j in range(sz):\n",
    "            #Probability of each bit flips\n",
    "            current_state[j] ^= random.random() < alpha\n",
    "            \n",
    "            if current_state[j] == 0:\n",
    "                #If the current bit is excluded, we add it to features to be excluded\n",
    "                drops.append(j)\n",
    "        \n",
    "        #Find score for the current state\n",
    "\n",
    "        cur_score = score(\n",
    "            np.delete(x_train, drops, 1),\n",
    "            np.delete(x_test, drops, 1),\n",
    "        )\n",
    "        \n",
    "        if cur_score > best[0]:\n",
    "            if verbose == 1:\n",
    "                print(\"Better subset found on generation \" + str(i) + \" with score of \" + str(cur_score))\n",
    "            best = (cur_score, current_state)\n",
    "        \n",
    "        if i % 25 == 0 and verbose == 2:\n",
    "            print(\"Generation \" + str(i) + \" completed\")\n",
    "            \n",
    "            \n",
    "    return best\n",
    "\n",
    "res = RHCSS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694be2d3-8273-425c-bc70-611e8fdad0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_scores = []\n",
    "testing_bitsets = []\n",
    "\n",
    "for i in range(100):\n",
    "    t = RHCSS()\n",
    "    testing_scores.append(t[0])\n",
    "    testing_bitsets.append(t[1])\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0fb53da-33a5-45e2-ba10-dd0ee19aade4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better subset found on generation 0 with score of 0.8657298985167837\n",
      "Better subset found on generation 0 with score of 0.8946135831381733\n",
      "Better subset found on generation 0 with score of 0.914519906323185\n",
      "Better subset found on generation 0 with score of 0.9215456674473068\n",
      "Better subset found on generation 0 with score of 0.9270101483216238\n",
      "Better subset found on generation 0 with score of 0.9336455893832943\n",
      "Better subset found on generation 0 with score of 0.9375487900078064\n",
      "Better subset found on generation 1 with score of 0.9430132708821234\n",
      "Better subset found on generation 11 with score of 0.9437939110070258\n",
      "Better subset found on generation 17 with score of 0.9445745511319282\n",
      "Better subset found on generation 26 with score of 0.9457455113192819\n",
      "Better subset found on generation 115 with score of 0.9480874316939891\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-6be66106f091>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRHCSS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-55-6be66106f091>\u001b[0m in \u001b[0;36mRHCSS\u001b[0;34m(generations, verbose)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m#Find score for the current state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             cur_score = score(\n\u001b[0m\u001b[1;32m     68\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-6be66106f091>\u001b[0m in \u001b[0;36mscore\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \"\"\"\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    899\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "\n",
    "#Randomized Hill Climbing Subset-Select Algorithm\n",
    "#Feature Selection based on Randomized Hill-Climbing Heuristic\n",
    "\n",
    "#Global Variables\n",
    "x_RHCSS = x\n",
    "y_RHCSS = y\n",
    "sz = x.shape[1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_RHCSS, y_RHCSS, test_size=0.2, random_state=69)\n",
    "\n",
    "#Alpha Level, [0, 0.5)\n",
    "alpha = 0.3\n",
    "#50% - a% to switch\n",
    "#50% + a% to remain\n",
    "\n",
    "evaluation_function = accuracy_score\n",
    "# model_algorithm = RandomForestClassifier\n",
    "model_algorithm = DecisionTreeClassifier\n",
    "\n",
    "def score(a, b):\n",
    "    if len(a) == 0:\n",
    "        #If we have no features (bitstring = 0), the score is automatically 0\n",
    "        return 0\n",
    "    \n",
    "    model = model_algorithm()\n",
    "    \n",
    "    model.fit(a, y_train)\n",
    "    \n",
    "    pred = model.predict(b)\n",
    "    #PREDICTION, Y_TEST OR OTHER WAY AROUND?\n",
    "    return evaluation_function(pred, y_test)\n",
    "    \n",
    "#Generation - Depth of the selection tree\n",
    "#We select the best children from each generation and continue with it\n",
    "\n",
    "def RHCSS(generations=1000, verbose = 1):\n",
    "    #Keep running track of the best state we found so far\n",
    "    #We use a bitset to represent wether the each feature is included\n",
    "    best = (0, [0] * sz)\n",
    "    \n",
    "    for i in range(generations):\n",
    "        genbest = best\n",
    "        \n",
    "        for k in range(50):\n",
    "            current_state = genbest[1]\n",
    "        \n",
    "            #The features to exclude\n",
    "            drops = []\n",
    "            for j in range(sz):\n",
    "                #Probability of each bit flips\n",
    "                current_state[j] ^= random.random() < (0.5 - alpha)\n",
    "\n",
    "                if current_state[j] == 0:\n",
    "                    #If the current bit is excluded, we add it to features to be excluded\n",
    "                    drops.append(j)\n",
    "\n",
    "            #Find score for the current state\n",
    "\n",
    "            cur_score = score(\n",
    "                np.delete(x_train, drops, 1),\n",
    "                np.delete(x_test, drops, 1),\n",
    "            )\n",
    "\n",
    "            if cur_score > best[0]:\n",
    "                if verbose == 1:\n",
    "                    print(\"Better subset found on generation \" + str(i) + \" with score of \" + str(cur_score))\n",
    "                best = (cur_score, current_state)\n",
    "        \n",
    "        if i % 25 == 0 and verbose == 2:\n",
    "            print(\"Generation \" + str(i) + \" completed\")\n",
    "            \n",
    "            \n",
    "    return best\n",
    "\n",
    "res = RHCSS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b04fb9-f399-495b-862b-daa020f73dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
